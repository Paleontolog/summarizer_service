version: '3.7'
services:

#  binary_classifier:
#    image: backend-binary-classifier
#    build: ./server
#    restart: always
#    environment:
#      - DEVICE=cpu
#      - MODEL_NAME=/home/backend/bert_model
#      - BACKEND_TYPE=binary_classifier
#      - BATCH_SIZE=32
#
#      - FLASK_APP=wsgi.py
#      - FLASK_ENV=production
#    volumes:
#      - ./bert_model:/home/backend/bert_model
#    command: gunicorn --bind 0.0.0.0:5000 wsgi:app
#    deploy:
#      resources:
#        reservations:
#          devices:
#            - driver: nvidia
#              count: 1
#              capabilities: [ gpu ]

  binary_classifier_triton:
    image: backend-binary-classifier_triton
    build: ./server_triton
    restart: always
    ports:
      - "8000:8000"
      - "8001:8001"
      - "8002:8002"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [ gpu ]


  bart_summarizer:
    build: ./server
    container_name: backend-bart-summarizer
    restart: always
    ports:
      - "8082:5000"
    environment:
      - DEVICE=cuda
      - MODEL_NAME=/home/backend/bart_model
      - BACKEND_TYPE=bart

      - FLASK_APP=wsgi.py
      - FLASK_ENV=production
    volumes:
      - ./bart_model:/home/backend/bart_model
    command: gunicorn --bind 0.0.0.0:5000 wsgi:app
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [ gpu ]


  backend_gui:
    build: ./gui
    image: backend-gui
    environment:
      - FLASK_APP=wsgi.py
      - FLASK_ENV=production

      - BINARY_CLASSIFIER=binary_classifier_triton:8000
      - BINARY_CLASSIFIER_TYPE=TRITON
      - SUMMARIZER=bart_summarizer:5000
    restart: always
    ports:
      - "8080:5000"
